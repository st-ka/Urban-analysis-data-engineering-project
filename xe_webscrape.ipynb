{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "653df602-28eb-46a9-9b34-cb99297a9ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4590\n"
     ]
    }
   ],
   "source": [
    "#Scraping xe.gr\n",
    "from bs4 import BeautifulSoup\n",
    "import httpx\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from zenrows import ZenRowsClient\n",
    "\n",
    "# RENTALS \n",
    "# Set the user-agent header\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "\n",
    "# Create a proxy client\n",
    "client = ZenRowsClient(\"a45285ef2974d1cf4c9f103296a7835b19844643\")\n",
    "BASE_URL='https://www.xe.gr/en/property/results?transaction_name=rent&item_type=re_residence&geo_place_ids%5B%5D=ChIJ8UNwBh-9oRQR3Y1mdkU1Nic'\n",
    "response = client.get(BASE_URL, headers=headers)\n",
    "soup=BeautifulSoup(response.content,\"html.parser\")\n",
    "\n",
    "# PAGINATION : Finding all li tags in ul and printing the text within it \n",
    "web_urls=[]\n",
    "nums=[]\n",
    "\n",
    "buttons=soup.find('ul',class_='results-pagination')\n",
    "for li in buttons.find_all('li'):\n",
    "    #print(li.text,end='')\n",
    "    nums.append(li.text.replace('\\n',''))\n",
    "\n",
    "# Take the last element from the list of texts found in li elements\n",
    "last_page=int(nums[-1])\n",
    "print(last_page*34)\n",
    "# Create the urls of multiple \"xe\" result pages, \n",
    "#for i in range(1,last_page+1):\n",
    "    #web_url_base=\"https://www.xe.gr/property/results?transaction_name=rent&item_type=re_residence&geo_place_ids%5B%5D=ChIJ8UNwBh-9oRQR3Y1mdkU1Nic&page=\"\n",
    "    #web_urls.append(web_url_base+str(i))\n",
    "    \n",
    "#print(web_urls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7dec94c4-0dbf-4007-b3d6-54291487cb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295\n",
      "10030\n"
     ]
    }
   ],
   "source": [
    "#SALES\n",
    "\n",
    "# Create an HTTPX client\n",
    "BASE_URL_Sales='https://www.xe.gr/property/results?transaction_name=buy&item_type=re_residence&geo_place_ids%5B%5D=ChIJ8UNwBh-9oRQR3Y1mdkU1Nic'\n",
    "response_Sales = client.get(BASE_URL_Sales, headers=headers)\n",
    "soup_Sales=BeautifulSoup(response_S.content,\"html.parser\")\n",
    "\n",
    "# PAGINATION : Finding all li tags in ul and printing the text within it \n",
    "num_Sales=[]\n",
    "buttons_Sales=soup_Sales.find('ul',class_='results-pagination')\n",
    "for li in buttons_Sales.find_all('li'):\n",
    "    #print(li.text,end='')\n",
    "    num_Sales.append(li.text.replace('\\n',''))\n",
    "\n",
    "# Take the last element from the list of texts found in li elements\n",
    "last_page_Sales=int(num_Sales[-1])\n",
    "print(last_page_Sales)\n",
    "\n",
    "num_of_ads_sales=last_page_Sales*34\n",
    "print(num_of_ads_sales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44273857-7c7f-4393-87e2-5cb59dee5c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for web_url in web_urls[3:5]:\n",
    "    \n",
    "    response=client.get(web_url,headers=headers)\n",
    "\n",
    "    xe_webpage=response.text\n",
    "\n",
    "    soup=BeautifulSoup(xe_webpage,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68bd13de-0ce1-4e11-ae86-f06a62915bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 13, 16, 22, 9, 16, 17, 8, 13, 11, 8, 10, 13, 7, 9, 17, 14, 9, 10, 11, 9, 7, 7, 7, 5, 27, 11, 8, 10, 8, 8, 5, 5, 13]\n",
      "34\n",
      "34\n",
      "35\n",
      "34\n",
      "34\n",
      "34\n",
      "    price                     title  \\\n",
      "0     460        Apartment 81 sq.m.   \n",
      "1    2200       Apartment 170 sq.m.   \n",
      "2    1200        Apartment 76 sq.m.   \n",
      "3    2750       Apartment 123 sq.m.   \n",
      "4     650        Apartment 69 sq.m.   \n",
      "5    2550       Apartment 157 sq.m.   \n",
      "6     850        Apartment 50 sq.m.   \n",
      "7     600        Apartment 75 sq.m.   \n",
      "8     520        Apartment 40 sq.m.   \n",
      "9     420        Apartment 38 sq.m.   \n",
      "10    580        Apartment 75 sq.m.   \n",
      "11    600        Apartment 60 sq.m.   \n",
      "12    350        Apartment 28 sq.m.   \n",
      "13    600        Apartment 85 sq.m.   \n",
      "14    650        Apartment 70 sq.m.   \n",
      "15    460        Apartment 27 sq.m.   \n",
      "16    720        Apartment 50 sq.m.   \n",
      "17    500        Apartment 55 sq.m.   \n",
      "18    830        Apartment 85 sq.m.   \n",
      "19    550        Apartment 51 sq.m.   \n",
      "20    600        Apartment 65 sq.m.   \n",
      "21    530        Apartment 72 sq.m.   \n",
      "22    580        Apartment 78 sq.m.   \n",
      "23    750       Apartment 104 sq.m.   \n",
      "24    600  Detached House 110 sq.m.   \n",
      "25   1600        Apartment 60 sq.m.   \n",
      "26    330        Apartment 30 sq.m.   \n",
      "27    650        Apartment 83 sq.m.   \n",
      "28    850        Apartment 85 sq.m.   \n",
      "29    450        Apartment 55 sq.m.   \n",
      "30    590        Apartment 71 sq.m.   \n",
      "31    460        Apartment 85 sq.m.   \n",
      "32    500  Detached House 110 sq.m.   \n",
      "33    400        Apartment 32 sq.m.   \n",
      "\n",
      "                                                  url              address  \\\n",
      "0   https://www.xe.gr/en/property/d/property-to-re...          Ano Patisia   \n",
      "1   https://www.xe.gr/en/property/d/property-to-re...           Lycabettus   \n",
      "2   https://www.xe.gr/en/property/d/property-to-re...          Monastiraki   \n",
      "3   https://www.xe.gr/en/property/d/property-to-re...             Kolonaki   \n",
      "4   https://www.xe.gr/en/property/d/property-to-re...        Ano Petralona   \n",
      "5   https://www.xe.gr/en/property/d/property-to-re...           Lycabettus   \n",
      "6   https://www.xe.gr/en/property/d/property-to-re...           Filopappou   \n",
      "7   https://www.xe.gr/en/property/d/property-to-re...              Kolonos   \n",
      "8   https://www.xe.gr/en/property/d/property-to-re...              Varnava   \n",
      "9   https://www.xe.gr/en/property/d/property-to-re...          Ano Kipseli   \n",
      "10  https://www.xe.gr/en/property/d/property-to-re...      Amerikis Square   \n",
      "11  https://www.xe.gr/en/property/d/property-to-re...         Metaxourgeio   \n",
      "12  https://www.xe.gr/en/property/d/property-to-re...       Agia Paraskevi   \n",
      "13  https://www.xe.gr/en/property/d/property-to-re...       Profitis Ilias   \n",
      "14  https://www.xe.gr/en/property/d/property-to-re...             Pagkrati   \n",
      "15  https://www.xe.gr/en/property/d/property-to-re...          Neos Kosmos   \n",
      "16  https://www.xe.gr/en/property/d/property-to-re...       Profitis Ilias   \n",
      "17  https://www.xe.gr/en/property/d/property-to-re...            Dourgouti   \n",
      "18  https://www.xe.gr/en/property/d/property-to-re...         Agios Thomas   \n",
      "19  https://www.xe.gr/en/property/d/property-to-re...  Agios Panteleimonas   \n",
      "20  https://www.xe.gr/en/property/d/property-to-re...         Agios Sostis   \n",
      "21  https://www.xe.gr/en/property/d/property-to-re...              Kypseli   \n",
      "22  https://www.xe.gr/en/property/d/property-to-re...       Agia Paraskevi   \n",
      "23  https://www.xe.gr/en/property/d/property-to-re...              Kypseli   \n",
      "24  https://www.xe.gr/en/property/d/property-to-re...    Akadimia Platonos   \n",
      "25  https://www.xe.gr/en/property/d/property-to-re...                Plaka   \n",
      "26  https://www.xe.gr/en/property/d/property-to-re...        Attica Square   \n",
      "27  https://www.xe.gr/en/property/d/property-to-re...          Nea Kypseli   \n",
      "28  https://www.xe.gr/en/property/d/property-to-re...           Filopappou   \n",
      "29  https://www.xe.gr/en/property/d/property-to-re...          Nea Kypseli   \n",
      "30  https://www.xe.gr/en/property/d/property-to-re...          Ampelokipoi   \n",
      "31  https://www.xe.gr/en/property/d/property-to-re...      Amerikis Square   \n",
      "32  https://www.xe.gr/en/property/d/property-to-re...     Pedion tou Areos   \n",
      "33  https://www.xe.gr/en/property/d/property-to-re...        Agios Ioannis   \n",
      "\n",
      "    price_sqm  \n",
      "0           6  \n",
      "1          13  \n",
      "2          16  \n",
      "3          22  \n",
      "4           9  \n",
      "5          16  \n",
      "6          17  \n",
      "7           8  \n",
      "8          13  \n",
      "9          11  \n",
      "10          8  \n",
      "11         10  \n",
      "12         13  \n",
      "13          7  \n",
      "14          9  \n",
      "15         17  \n",
      "16         14  \n",
      "17          9  \n",
      "18         10  \n",
      "19         11  \n",
      "20          9  \n",
      "21          7  \n",
      "22          7  \n",
      "23          7  \n",
      "24          5  \n",
      "25         27  \n",
      "26         11  \n",
      "27          8  \n",
      "28         10  \n",
      "29          8  \n",
      "30          8  \n",
      "31          5  \n",
      "32          5  \n",
      "33         13  \n"
     ]
    }
   ],
   "source": [
    "# Access page source code, parse, find elements and write them in csv file \n",
    "\n",
    "\n",
    "\n",
    "price_list=[]\n",
    "title_list=[]\n",
    "level_list=[]\n",
    "url_list=[]\n",
    "address_list=[]\n",
    "price_sqm_list=[]\n",
    "\n",
    "\n",
    "\n",
    "prices=soup.find_all(name=\"span\",class_=\"property-ad-price\")\n",
    "titles=soup.find_all(name=\"div\",class_=\"common-property-ad-title\")\n",
    "levels=soup.find_all(name=\"span\",class_=\"property-ad-level\")\n",
    "url_element=soup.find_all(name=\"div\",class_=\"common-property-ad-body grid-y align-justify\")\n",
    "addresses=soup.find_all(name=\"span\",class_=\"common-property-ad-address\")\n",
    "prices_sqm=soup.find_all(name=\"span\",class_=\"property-ad-price-per-sqm\")\n",
    "\n",
    "for price in prices:\n",
    "    p=re.findall(r'\\d+', price.getText())\n",
    "    price_list.append(int(\"\".join(p)))\n",
    "   #price_list.append(price.getText().replace(\"\\xa0\",\" \")) \n",
    "\n",
    "for title in titles:\n",
    "    title_list.append(title.getText().replace(\"\\n\",\"\"))\n",
    "\n",
    "for level in levels:\n",
    "    y1=level.getText().replace(\"\\n\",\"\")\n",
    "    level_list.append(y1.replace(\" \", \"\"))\n",
    "    \n",
    "for urlz in url_element:\n",
    "    urls=urlz.find('a')\n",
    "    url_list.append(urls.get('href'))\n",
    "\n",
    "for address in addresses:\n",
    "    address_clean=re.findall(r'\\((.*?)\\)',address.getText())\n",
    "    address_list.append(address_clean[0])\n",
    "    #address_clean=address.getText().replace(\" \", \"\")\n",
    "    #address_list.append(address_clean.replace(\"\\n\",\"\"))  \n",
    "\n",
    "for price_sqm in prices_sqm:\n",
    "    psqm=re.findall(r'\\d+', price_sqm.getText())\n",
    "    price_sqm_list.append(int(\"\".join(psqm)))\n",
    "    #price_sqm_list.append((price_sqm.getText().replace(\"\\xa0\",\"\")).replace(\"\\n\",\"\"))\n",
    "\n",
    "#print(price_list)\n",
    "#print(title_list)\n",
    "#print(level_list)\n",
    "#print(url_list)\n",
    "#print(address_list)\n",
    "print(price_sqm_list)\n",
    "print(len(price_list))\n",
    "print(len(title_list))\n",
    "print(len(level_list))\n",
    "print(len(url_list))\n",
    "print(len(address_list))\n",
    "print(len(price_sqm_list))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Create dictionary with column names as keys\n",
    "#data={'Title':title_list,'Price':price_list,'URL':url_list}\n",
    "\n",
    "#create dataframe\n",
    "df=pd.DataFrame(list(zip(price_list,title_list,url_list,address_list,price_sqm_list)), columns=['price','title','url','address','price_sqm'])\n",
    "print(df)\n",
    "#write to csv file\n",
    "df.to_csv('xe.gr',mode='a',index=False, header=False)\n",
    "\n",
    "time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e91c3cc-ada6-4863-87db-4b8bf17f2306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access page source code, parse, find elements and write them in csv file \n",
    "\n",
    "for web_url in web_urls:\n",
    "    \n",
    "    response=client.get(web_url,headers=headers)\n",
    "\n",
    "    xe_webpage=response.text\n",
    "\n",
    "    soup=BeautifulSoup(xe_webpage,\"html.parser\")\n",
    "\n",
    "    price_list=[]\n",
    "    title_list=[]\n",
    "    level_list=[]\n",
    "    url_list=[]\n",
    "    address_list=[]\n",
    "\n",
    "    \n",
    "    prices=soup.find_all(name=\"span\",class_=\"property-ad-price\")\n",
    "    titles=soup.find_all(name=\"div\",class_=\"common-property-ad-title\")\n",
    "    levels=soup.find_all(name=\"span\",class_=\"property-ad-level\")\n",
    "    url_element=soup.find_all(name=\"div\",class_=\"common-property-ad-body grid-y align-justify\")\n",
    "    addresses=soup.find_all(name=\"span\",class_=\"common-property-ad-address\")\n",
    "\n",
    "    for price in prices:\n",
    "       price_list.append(price.getText().replace(\"\\xa0\",\" \")) \n",
    "\n",
    "    for title in titles:\n",
    "        title_list.append(title.getText().replace(\"\\n\",\"\"))\n",
    "\n",
    "    for level in levels:\n",
    "        y1=level.getText().replace(\"\\n\",\"\")\n",
    "        level_list.append(y1.replace(\" \", \"\"))\n",
    "        \n",
    "    for urlz in url_element:\n",
    "        urls=urlz.find('a')\n",
    "        url_list.append(urls.get('href'))\n",
    "\n",
    "    for address in addresses:\n",
    "        address_clean=address.getText().replace(\" \", \"\")\n",
    "        address_list.append(address_clean.replace(\"\\n\",\"\"))  \n",
    "    \n",
    "    print(price_list)\n",
    "    print(title_list)\n",
    "    print(level_list)\n",
    "    print(url_list)\n",
    "    print(address_list)\n",
    "    print(len(price_list))\n",
    "    print(len(title_list))\n",
    "    print(len(level_list))\n",
    "    print(len(url_list))\n",
    "\n",
    "\n",
    "\n",
    "    #Create dictionary with column names as keys\n",
    "    data={'Title':title_list,'Price':price_list,'URL':url_list}\n",
    "\n",
    "    #create dataframe\n",
    "    df=pd.DataFrame(data)\n",
    "\n",
    "    #write to csv file\n",
    "    df.to_csv('xe.gr',mode='a',index=False, header=False)\n",
    "\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc748c-4b9b-4d12-a586-46208459e8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
