{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "653df602-28eb-46a9-9b34-cb99297a9ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4590\n"
     ]
    }
   ],
   "source": [
    "#Scraping xe.gr\n",
    "from bs4 import BeautifulSoup\n",
    "import httpx\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "\n",
    "\n",
    "# RENTALS \n",
    "# Set the user-agent header\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "\n",
    "# Create an HTTPX client\n",
    "client = httpx.Client()\n",
    "BASE_URL='https://www.xe.gr/en/property/results?transaction_name=rent&item_type=re_residence&geo_place_ids%5B%5D=ChIJ8UNwBh-9oRQR3Y1mdkU1Nic'\n",
    "response = httpx.get(BASE_URL, headers=headers)\n",
    "soup1=BeautifulSoup(response.content,\"html.parser\")\n",
    "\n",
    "# PAGINATION : Finding all li tags in ul and printing the text within it \n",
    "web_urls=[]\n",
    "nums=[]\n",
    "\n",
    "buttons=soup.find('ul',class_='results-pagination')\n",
    "for li in buttons.find_all('li'):\n",
    "    #print(li.text,end='')\n",
    "    nums.append(li.text.replace('\\n',''))\n",
    "\n",
    "# Take the last element from the list of texts found in li elements\n",
    "last_page=int(nums[-1])\n",
    "print(last_page*34)\n",
    "# Create the urls of multiple \"xe\" result pages, \n",
    "#for i in range(1,last_page+1):\n",
    "    #web_url_base=\"https://www.xe.gr/property/results?transaction_name=rent&item_type=re_residence&geo_place_ids%5B%5D=ChIJ8UNwBh-9oRQR3Y1mdkU1Nic&page=\"\n",
    "    #web_urls.append(web_url_base+str(i))\n",
    "    \n",
    "#print(web_urls)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7dec94c4-0dbf-4007-b3d6-54291487cb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295\n",
      "10030\n"
     ]
    }
   ],
   "source": [
    "#SALES\n",
    "\n",
    "# Set the user-agent header\n",
    "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}\n",
    "\n",
    "# Create an HTTPX client\n",
    "client = httpx.Client()\n",
    "BASE_URL_S='https://www.xe.gr/property/results?transaction_name=buy&item_type=re_residence&geo_place_ids%5B%5D=ChIJ8UNwBh-9oRQR3Y1mdkU1Nic'\n",
    "response_S = httpx.get(BASE_URL_S, headers=headers)\n",
    "soup_S=BeautifulSoup(response_S.content,\"html.parser\")\n",
    "\n",
    "# PAGINATION : Finding all li tags in ul and printing the text within it \n",
    "buttons_S=soup_S.find('ul',class_='results-pagination')\n",
    "for li in buttons_S.find_all('li'):\n",
    "    #print(li.text,end='')\n",
    "    nums_S.append(li.text.replace('\\n',''))\n",
    "\n",
    "# Take the last element from the list of texts found in li elements\n",
    "last_page_S=int(nums[-1])\n",
    "print(last_page_S)\n",
    "\n",
    "num_of_ads_sales=last_page_S*34\n",
    "print(num_of_ads_sales)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "44273857-7c7f-4393-87e2-5cb59dee5c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "for web_url in web_urls[3:5]:\n",
    "    \n",
    "    response=client.get(web_url,headers=headers)\n",
    "\n",
    "    xe_webpage=response.text\n",
    "\n",
    "    soup=BeautifulSoup(xe_webpage,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68bd13de-0ce1-4e11-ae86-f06a62915bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17, 8, 11, 7, 15, 22, 12, 5, 8, 18, 10, 8, 7, 9, 10, 11, 3, 12, 9, 7, 10, 2193, 7, 14, 8, 10, 9, 7, 8, 9, 13, 8, 9, 14]\n",
      "34\n",
      "34\n",
      "36\n",
      "34\n",
      "34\n",
      "34\n",
      "     price                  title  \\\n",
      "0     1450     Διαμέρισμα 85 τ.μ.   \n",
      "1      550     Διαμέρισμα 73 τ.μ.   \n",
      "2      550     Διαμέρισμα 51 τ.μ.   \n",
      "3      850    Διαμέρισμα 115 τ.μ.   \n",
      "4     1110     Διαμέρισμα 75 τ.μ.   \n",
      "5     1300     Διαμέρισμα 60 τ.μ.   \n",
      "6      800     Διαμέρισμα 67 τ.μ.   \n",
      "7      450     Διαμέρισμα 85 τ.μ.   \n",
      "8      650     Διαμέρισμα 83 τ.μ.   \n",
      "9      620     Διαμέρισμα 34 τ.μ.   \n",
      "10     600     Διαμέρισμα 60 τ.μ.   \n",
      "11     780    Διαμέρισμα 100 τ.μ.   \n",
      "12    1200    Διαμέρισμα 165 τ.μ.   \n",
      "13     600     Διαμέρισμα 70 τ.μ.   \n",
      "14    1300    Διαμέρισμα 129 τ.μ.   \n",
      "15     570     Διαμέρισμα 53 τ.μ.   \n",
      "16    1200  Μονοκατοικία 400 τ.μ.   \n",
      "17    1000     Διαμέρισμα 82 τ.μ.   \n",
      "18     500     Διαμέρισμα 53 τ.μ.   \n",
      "19     490     Διαμέρισμα 70 τ.μ.   \n",
      "20     830     Διαμέρισμα 85 τ.μ.   \n",
      "21  125000     Διαμέρισμα 57 τ.μ.   \n",
      "22     780    Διαμέρισμα 106 τ.μ.   \n",
      "23     400     Διαμέρισμα 29 τ.μ.   \n",
      "24     800    Διαμέρισμα 100 τ.μ.   \n",
      "25     700     Διαμέρισμα 67 τ.μ.   \n",
      "26     720     Διαμέρισμα 80 τ.μ.   \n",
      "27     500     Διαμέρισμα 75 τ.μ.   \n",
      "28     550     Διαμέρισμα 70 τ.μ.   \n",
      "29     680     Διαμέρισμα 80 τ.μ.   \n",
      "30     550     Διαμέρισμα 44 τ.μ.   \n",
      "31     650     Διαμέρισμα 80 τ.μ.   \n",
      "32     650     Διαμέρισμα 75 τ.μ.   \n",
      "33    1000     Διαμέρισμα 70 τ.μ.   \n",
      "\n",
      "                                                  url                address  \\\n",
      "0   https://www.xe.gr/property/d/enoikiaseis-katoi...             [Κολωνάκι]   \n",
      "1   https://www.xe.gr/property/d/enoikiaseis-katoi...     [Πλατεία Αμερικής]   \n",
      "2   https://www.xe.gr/property/d/enoikiaseis-katoi...  [Άγιος Παντελεήμονας]   \n",
      "3   https://www.xe.gr/property/d/enoikiaseis-katoi...    [Πλατεία Βικτωρίας]   \n",
      "4   https://www.xe.gr/property/d/enoikiaseis-katoi...              [Βαρνάβα]   \n",
      "5   https://www.xe.gr/property/d/enoikiaseis-katoi...                [Γκάζι]   \n",
      "6   https://www.xe.gr/property/d/enoikiaseis-katoi...         [Λόφος Στρέφη]   \n",
      "7   https://www.xe.gr/property/d/enoikiaseis-katoi...         [Μεταξουργείο]   \n",
      "8   https://www.xe.gr/property/d/enoikiaseis-katoi...           [Νέα Κυψέλη]   \n",
      "9   https://www.xe.gr/property/d/enoikiaseis-katoi...       [Κάτω Πετράλωνα]   \n",
      "10  https://www.xe.gr/property/d/enoikiaseis-katoi...         [Μεταξουργείο]   \n",
      "11  https://www.xe.gr/property/d/enoikiaseis-katoi...      [Πλατεία Αττικής]   \n",
      "12  https://www.xe.gr/property/d/enoikiaseis-katoi...             [Παγκράτι]   \n",
      "13  https://www.xe.gr/property/d/enoikiaseis-katoi...              [Κουκάκι]   \n",
      "14  https://www.xe.gr/property/d/enoikiaseis-katoi...             [Παγκράτι]   \n",
      "15  https://www.xe.gr/property/d/enoikiaseis-katoi...       [Κάτω Πετράλωνα]   \n",
      "16  https://www.xe.gr/property/d/enoikiaseis-katoi...         [Μεταξουργείο]   \n",
      "17  https://www.xe.gr/property/d/enoikiaseis-katoi...           [Λυκαβηττός]   \n",
      "18  https://www.xe.gr/property/d/enoikiaseis-katoi...             [Μπακνανά]   \n",
      "19  https://www.xe.gr/property/d/enoikiaseis-katoi...         [Λόφος Σκουζέ]   \n",
      "20  https://www.xe.gr/property/d/enoikiaseis-katoi...          [Άγιος Θωμάς]   \n",
      "21  https://www.xe.gr/property/d/enoikiaseis-katoi...              [Ηπείρου]   \n",
      "22  https://www.xe.gr/property/d/enoikiaseis-katoi...         [Πεδίον Άρεως]   \n",
      "23  https://www.xe.gr/property/d/enoikiaseis-katoi...      [Πλατεία Αττικής]   \n",
      "24  https://www.xe.gr/property/d/enoikiaseis-katoi...    [Πλατεία Βικτωρίας]   \n",
      "25  https://www.xe.gr/property/d/enoikiaseis-katoi...           [Γηροκομείο]   \n",
      "26  https://www.xe.gr/property/d/enoikiaseis-katoi...          [Αμπελόκηποι]   \n",
      "27  https://www.xe.gr/property/d/enoikiaseis-katoi...      [Πλατεία Αττικής]   \n",
      "28  https://www.xe.gr/property/d/enoikiaseis-katoi...            [Βοτανικός]   \n",
      "29  https://www.xe.gr/property/d/enoikiaseis-katoi...       [Άγιος Νικόλαος]   \n",
      "30  https://www.xe.gr/property/d/enoikiaseis-katoi...       [Άγιος Νικόλαος]   \n",
      "31  https://www.xe.gr/property/d/enoikiaseis-katoi...            [Κολιάτσου]   \n",
      "32  https://www.xe.gr/property/d/enoikiaseis-katoi...        [Τρεις Γέφυρες]   \n",
      "33  https://www.xe.gr/property/d/enoikiaseis-katoi...               [Ιλίσια]   \n",
      "\n",
      "    price_sqm  \n",
      "0          17  \n",
      "1           8  \n",
      "2          11  \n",
      "3           7  \n",
      "4          15  \n",
      "5          22  \n",
      "6          12  \n",
      "7           5  \n",
      "8           8  \n",
      "9          18  \n",
      "10         10  \n",
      "11          8  \n",
      "12          7  \n",
      "13          9  \n",
      "14         10  \n",
      "15         11  \n",
      "16          3  \n",
      "17         12  \n",
      "18          9  \n",
      "19          7  \n",
      "20         10  \n",
      "21       2193  \n",
      "22          7  \n",
      "23         14  \n",
      "24          8  \n",
      "25         10  \n",
      "26          9  \n",
      "27          7  \n",
      "28          8  \n",
      "29          9  \n",
      "30         13  \n",
      "31          8  \n",
      "32          9  \n",
      "33         14  \n"
     ]
    }
   ],
   "source": [
    "# Access page source code, parse, find elements and write them in csv file \n",
    "\n",
    "\n",
    "\n",
    "price_list=[]\n",
    "title_list=[]\n",
    "level_list=[]\n",
    "url_list=[]\n",
    "address_list=[]\n",
    "price_sqm_list=[]\n",
    "\n",
    "\n",
    "\n",
    "prices=soup.find_all(name=\"span\",class_=\"property-ad-price\")\n",
    "titles=soup.find_all(name=\"div\",class_=\"common-property-ad-title\")\n",
    "levels=soup.find_all(name=\"span\",class_=\"property-ad-level\")\n",
    "url_element=soup.find_all(name=\"div\",class_=\"common-property-ad-body grid-y align-justify\")\n",
    "addresses=soup.find_all(name=\"span\",class_=\"common-property-ad-address\")\n",
    "prices_sqm=soup.find_all(name=\"span\",class_=\"property-ad-price-per-sqm\")\n",
    "\n",
    "for price in prices:\n",
    "    p=re.findall(r'\\d+', price.getText())\n",
    "    price_list.append(int(\"\".join(p)))\n",
    "   #price_list.append(price.getText().replace(\"\\xa0\",\" \")) \n",
    "\n",
    "for title in titles:\n",
    "    title_list.append(title.getText().replace(\"\\n\",\"\"))\n",
    "\n",
    "for level in levels:\n",
    "    y1=level.getText().replace(\"\\n\",\"\")\n",
    "    level_list.append(y1.replace(\" \", \"\"))\n",
    "    \n",
    "for urlz in url_element:\n",
    "    urls=urlz.find('a')\n",
    "    url_list.append(urls.get('href'))\n",
    "\n",
    "for address in addresses:\n",
    "    address_clean=re.findall(r'\\((.*?)\\)',address.getText())\n",
    "    address_list.append(address_clean)\n",
    "    #address_clean=address.getText().replace(\" \", \"\")\n",
    "    #address_list.append(address_clean.replace(\"\\n\",\"\"))  \n",
    "\n",
    "for price_sqm in prices_sqm:\n",
    "    psqm=re.findall(r'\\d+', price_sqm.getText())\n",
    "    price_sqm_list.append(int(\"\".join(psqm)))\n",
    "    #price_sqm_list.append((price_sqm.getText().replace(\"\\xa0\",\"\")).replace(\"\\n\",\"\"))\n",
    "\n",
    "#print(price_list)\n",
    "#print(title_list)\n",
    "#print(level_list)\n",
    "#print(url_list)\n",
    "#print(address_list)\n",
    "print(price_sqm_list)\n",
    "print(len(price_list))\n",
    "print(len(title_list))\n",
    "print(len(level_list))\n",
    "print(len(url_list))\n",
    "print(len(address_list))\n",
    "print(len(price_sqm_list))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Create dictionary with column names as keys\n",
    "#data={'Title':title_list,'Price':price_list,'URL':url_list}\n",
    "\n",
    "#create dataframe\n",
    "df=pd.DataFrame(list(zip(price_list,title_list,url_list,address_list,price_sqm_list)), columns=['price','title','url','address','price_sqm'])\n",
    "print(df)\n",
    "#write to csv file\n",
    "#df.to_csv('xe.gr',mode='a',index=False, header=False)\n",
    "\n",
    "time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e91c3cc-ada6-4863-87db-4b8bf17f2306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access page source code, parse, find elements and write them in csv file \n",
    "\n",
    "for web_url in web_urls:\n",
    "    \n",
    "    response=client.get(web_url,headers=headers)\n",
    "\n",
    "    xe_webpage=response.text\n",
    "\n",
    "    soup=BeautifulSoup(xe_webpage,\"html.parser\")\n",
    "\n",
    "    price_list=[]\n",
    "    title_list=[]\n",
    "    level_list=[]\n",
    "    url_list=[]\n",
    "    address_list=[]\n",
    "\n",
    "    \n",
    "    prices=soup.find_all(name=\"span\",class_=\"property-ad-price\")\n",
    "    titles=soup.find_all(name=\"div\",class_=\"common-property-ad-title\")\n",
    "    levels=soup.find_all(name=\"span\",class_=\"property-ad-level\")\n",
    "    url_element=soup.find_all(name=\"div\",class_=\"common-property-ad-body grid-y align-justify\")\n",
    "    addresses=soup.find_all(name=\"span\",class_=\"common-property-ad-address\")\n",
    "\n",
    "    for price in prices:\n",
    "       price_list.append(price.getText().replace(\"\\xa0\",\" \")) \n",
    "\n",
    "    for title in titles:\n",
    "        title_list.append(title.getText().replace(\"\\n\",\"\"))\n",
    "\n",
    "    for level in levels:\n",
    "        y1=level.getText().replace(\"\\n\",\"\")\n",
    "        level_list.append(y1.replace(\" \", \"\"))\n",
    "        \n",
    "    for urlz in url_element:\n",
    "        urls=urlz.find('a')\n",
    "        url_list.append(urls.get('href'))\n",
    "\n",
    "    for address in addresses:\n",
    "        address_clean=address.getText().replace(\" \", \"\")\n",
    "        address_list.append(address_clean.replace(\"\\n\",\"\"))  \n",
    "    \n",
    "    print(price_list)\n",
    "    print(title_list)\n",
    "    print(level_list)\n",
    "    print(url_list)\n",
    "    print(address_list)\n",
    "    print(len(price_list))\n",
    "    print(len(title_list))\n",
    "    print(len(level_list))\n",
    "    print(len(url_list))\n",
    "\n",
    "\n",
    "\n",
    "    #Create dictionary with column names as keys\n",
    "    data={'Title':title_list,'Price':price_list,'URL':url_list}\n",
    "\n",
    "    #create dataframe\n",
    "    df=pd.DataFrame(data)\n",
    "\n",
    "    #write to csv file\n",
    "    df.to_csv('xe.gr',mode='a',index=False, header=False)\n",
    "\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc748c-4b9b-4d12-a586-46208459e8f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
